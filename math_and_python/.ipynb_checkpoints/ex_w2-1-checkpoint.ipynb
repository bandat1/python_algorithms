{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 1: сравнение предложений\n",
    "Дан набор предложений, скопированных с Википедии. Каждое из них имеет \"кошачью тему\" в одном из трех смыслов:\n",
    "\n",
    "кошки (животные)\n",
    "UNIX-утилита cat для вывода содержимого файлов\n",
    "версии операционной системы OS X, названные в честь семейства кошачьих\n",
    "Ваша задача — найти два предложения, которые ближе всего по смыслу к расположенному в самой первой строке. В качестве меры близости по смыслу мы будем использовать косинусное расстояние.\n",
    "\n",
    "sentences.txt\n",
    "Выполните следующие шаги:\n",
    "\n",
    "Скачайте файл с предложениями (sentences.txt).\n",
    "Каждая строка в файле соответствует одному предложению. Считайте их, приведите каждую к нижнему регистру с помощью строковой функции lower().\n",
    "Произведите токенизацию, то есть разбиение текстов на слова. Для этого можно воспользоваться регулярным выражением, которое считает разделителем любой символ, не являющийся буквой: re.split('[^a-z]', t). Не забудьте удалить пустые слова после разделения.\n",
    "Составьте список всех слов, встречающихся в предложениях. Сопоставьте каждому слову индекс от нуля до (d - 1), где d — число различных слов в предложениях. Для этого удобно воспользоваться структурой dict.\n",
    "Создайте матрицу размера n * d, где n — число предложений. Заполните ее: элемент с индексом (i, j) в этой матрице должен быть равен количеству вхождений j-го слова в i-е предложение. У вас должна получиться матрица размера 22 * 254.\n",
    "Найдите косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) до всех остальных с помощью функции scipy.spatial.distance.cosine. Какие номера у двух предложений, ближайших к нему по этому расстоянию (строки нумеруются с нуля)? Эти два числа и будут ответами на задание. Само предложение (In comparison to dogs, cats have not undergone... ) имеет индекс 0.\n",
    "Запишите полученные числа в файл, разделив пробелом. Обратите внимание, что файл должен состоять из одной строки, в конце которой не должно быть переноса. Пример файла с решением вы можете найти в конце задания (submission-1.txt).\n",
    "Совпадают ли ближайшие два предложения по тематике с первым? Совпадают ли тематики у следующих по близости предложений?\n",
    "Разумеется, использованный вами метод крайне простой. Например, он не учитывает формы слов (так, cat и cats он считает разными словами, хотя по сути они означают одно и то же), не удаляет из текстов артикли и прочие ненужные слова. Позже мы будем подробно изучать анализ текстов, где выясним, как достичь высокого качества в задаче поиска похожих предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_f = open('C:\\Users\\leonov\\Documents\\PythonScripts\\sentences.txt', 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = my_f.xreadlines()\n",
    "a = (str.read().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "b = re.split('[^a-z]', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'comparison', 'to', 'dogs', 'cats', 'have', 'not', 'undergone', 'major', 'changes', 'during', 'the', 'domestication', 'process', 'as', 'cat', 'simply', 'catenates', 'streams', 'of', 'bytes', 'it', 'can', 'be', 'also', 'used', 'to', 'concatenate', 'binary', 'files', 'where', 'it', 'will', 'just', 'concatenate', 'sequence', 'of', 'bytes', 'a', 'common', 'interactive', 'use', 'of', 'cat', 'for', 'a', 'single', 'file', 'is', 'to', 'output', 'the', 'content', 'of', 'a', 'file', 'to', 'standard', 'output', 'cats', 'can', 'hear', 'sounds', 'too', 'faint', 'or', 'too', 'high', 'in', 'frequency', 'for', 'human', 'ears', 'such', 'as', 'those', 'made', 'by', 'mice', 'and', 'other', 'small', 'animals', 'in', 'one', 'people', 'deliberately', 'tamed', 'cats', 'in', 'a', 'process', 'of', 'artificial', 'selection', 'as', 'they', 'were', 'useful', 'predators', 'of', 'vermin', 'the', 'domesticated', 'cat', 'and', 'its', 'closest', 'wild', 'ancestor', 'are', 'both', 'diploid', 'organisms', 'that', 'possess', 'chromosomes', 'and', 'roughly', 'genes', 'domestic', 'cats', 'are', 'similar', 'in', 'size', 'to', 'the', 'other', 'members', 'of', 'the', 'genus', 'felis', 'typically', 'weighing', 'between', 'and', 'kg', 'and', 'lb', 'however', 'if', 'the', 'output', 'is', 'piped', 'or', 'redirected', 'cat', 'is', 'unnecessary', 'cat', 'with', 'one', 'named', 'file', 'is', 'safer', 'where', 'human', 'error', 'is', 'a', 'concern', 'one', 'wrong', 'use', 'of', 'the', 'default', 'redirection', 'symbol', 'instead', 'of', 'often', 'adjacent', 'on', 'keyboards', 'may', 'permanently', 'delete', 'the', 'file', 'you', 'were', 'just', 'needing', 'to', 'read', 'in', 'terms', 'of', 'legibility', 'a', 'sequence', 'of', 'commands', 'starting', 'with', 'cat', 'and', 'connected', 'by', 'pipes', 'has', 'a', 'clear', 'left', 'to', 'right', 'flow', 'of', 'information', 'cat', 'command', 'is', 'one', 'of', 'the', 'basic', 'commands', 'that', 'you', 'learned', 'when', 'you', 'started', 'in', 'the', 'unix', 'linux', 'world', 'using', 'cat', 'command', 'the', 'lines', 'received', 'from', 'stdin', 'can', 'be', 'redirected', 'to', 'a', 'new', 'file', 'using', 'redirection', 'symbols', 'when', 'you', 'type', 'simply', 'cat', 'command', 'without', 'any', 'arguments', 'it', 'just', 'receives', 'the', 'stdin', 'content', 'and', 'displays', 'it', 'in', 'the', 'stdout', 'leopard', 'was', 'released', 'on', 'october', 'as', 'the', 'successor', 'of', 'tiger', 'version', 'and', 'is', 'available', 'in', 'two', 'editions', 'according', 'to', 'apple', 'leopard', 'contains', 'over', 'changes', 'and', 'enhancements', 'over', 'its', 'predecessor', 'mac', 'os', 'x', 'tiger', 'as', 'of', 'mid', 'some', 'apple', 'computers', 'have', 'firmware', 'factory', 'installed', 'which', 'will', 'no', 'longer', 'allow', 'installation', 'of', 'mac', 'os', 'x', 'leopard', 'since', 'apple', 'moved', 'to', 'using', 'intel', 'processors', 'in', 'their', 'computers', 'the', 'osx', 'community', 'has', 'developed', 'and', 'now', 'also', 'allows', 'mac', 'os', 'x', 'tiger', 'and', 'later', 'releases', 'to', 'be', 'installed', 'on', 'non', 'apple', 'x', 'based', 'computers', 'os', 'x', 'mountain', 'lion', 'was', 'released', 'on', 'july', 'for', 'purchase', 'and', 'download', 'through', 'apple', 's', 'mac', 'app', 'store', 'as', 'part', 'of', 'a', 'switch', 'to', 'releasing', 'os', 'x', 'versions', 'online', 'and', 'every', 'year', 'apple', 'has', 'released', 'a', 'small', 'patch', 'for', 'the', 'three', 'most', 'recent', 'versions', 'of', 'safari', 'running', 'on', 'os', 'x', 'yosemite', 'mavericks', 'and', 'mountain', 'lion', 'the', 'mountain', 'lion', 'release', 'marks', 'the', 'second', 'time', 'apple', 'has', 'offered', 'an', 'incremental', 'upgrade', 'rather', 'than', 'releasing', 'a', 'new', 'cat', 'entirely', 'mac', 'os', 'x', 'mountain', 'lion', 'installs', 'in', 'place', 'so', 'you', 'won', 't', 'need', 'to', 'create', 'a', 'separate', 'disk', 'or', 'run', 'the', 'installation', 'off', 'an', 'external', 'drive', 'the', 'fifth', 'major', 'update', 'to', 'mac', 'os', 'x', 'leopard', 'contains', 'such', 'a', 'mountain', 'of', 'features', 'more', 'than', 'by', 'apple', 's', 'count']\n"
     ]
    }
   ],
   "source": [
    "d = [x for x in b if x]\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'displays': 155, 'osx': 192, 'selection': 67, 'safari': 221, 'just': 31, 'developed': 194, 'over': 170, 'vermin': 72, 'domestic': 87, 'named': 104, 'installed': 181, 'symbols': 149, 'through': 206, 'human': 51, 'world': 142, 'disk': 244, 'its': 74, 'fifth': 249, 'features': 251, 'tamed': 65, 'upgrade': 232, 'lb': 97, 'drive': 248, 'to': 2, 'won': 239, 'deliberately': 64, 'marks': 226, 'has': 129, 'predecessor': 172, 'non': 199, 'which': 182, 'read': 122, 'october': 160, 'every': 215, 'os': 174, 'they': 68, 'not': 6, 'during': 10, 'now': 195, 'possess': 83, 'intel': 189, 'keyboards': 116, 'bytes': 20, 'unnecessary': 102, 'patch': 217, 'predators': 71, 'small': 60, 'output': 41, 'entirely': 235, 'where': 29, 'ears': 52, 'available': 164, 'on': 115, 'often': 113, 'sequence': 32, 'some': 177, 'lion': 202, 'frequency': 50, 'are': 78, 'year': 216, 'download': 205, 'terms': 123, 'concern': 107, 'error': 106, 'for': 37, 'pipes': 128, 'since': 187, 'factory': 180, 'artificial': 66, 'content': 42, 'version': 163, 'run': 245, 'between': 95, 'new': 148, 'learned': 137, 'three': 218, 'piped': 100, 'common': 34, 'concatenate': 26, 'be': 23, 'weighing': 94, 'genes': 86, 'use': 36, 'standard': 43, 'release': 225, 'diploid': 80, 'members': 90, 'x': 175, 'based': 200, 'safer': 105, 'by': 56, 'both': 79, 'commands': 125, 'installation': 186, 'installs': 236, 'of': 19, 'needing': 121, 'allows': 196, 'according': 167, 'july': 203, 'later': 197, 'mac': 173, 's': 207, 'streams': 18, 'receives': 154, 'successor': 161, 'catenates': 17, 'changes': 9, 'or': 48, 'felis': 92, 'major': 8, 'faint': 47, 'useful': 70, 'apple': 168, 'app': 208, 'community': 193, 'one': 62, 'running': 222, 'unix': 140, 'right': 132, 'simply': 16, 'linux': 141, 'sounds': 45, 'size': 89, 'undergone': 7, 'delete': 119, 'from': 146, 'enhancements': 171, 'second': 227, 'their': 191, 'create': 242, 'people': 63, 'two': 165, 't': 240, 'redirection': 110, 'however': 98, 'cats': 4, 'too': 46, 'basic': 136, 'permanently': 118, 'type': 150, 'dogs': 3, 'store': 209, 'more': 252, 'files': 28, 'releases': 198, 'that': 82, 'started': 139, 'contains': 169, 'releasing': 212, 'tiger': 162, 'released': 159, 'part': 210, 'hear': 44, 'external': 247, 'editions': 166, 'off': 246, 'mice': 57, 'with': 103, 'than': 234, 'those': 54, 'longer': 184, 'count': 253, 'made': 55, 'animals': 61, 'mavericks': 224, 'versions': 213, 'default': 109, 'was': 158, 'single': 38, 'cat': 15, 'will': 30, 'can': 22, 'were': 69, 'wild': 76, 'similar': 88, 'interactive': 35, 'and': 58, 'mountain': 201, 'computers': 178, 'have': 5, 'stdout': 156, 'process': 13, 'lines': 144, 'is': 40, 'received': 145, 'moved': 188, 'it': 21, 'an': 230, 'high': 49, 'as': 14, 'incremental': 231, 'file': 39, 'in': 0, 'need': 241, 'domesticated': 73, 'any': 152, 'domestication': 12, 'if': 99, 'binary': 27, 'processors': 190, 'no': 183, 'rather': 233, 'legibility': 124, 'separate': 243, 'firmware': 179, 'when': 138, 'mid': 176, 'also': 24, 'other': 59, 'arguments': 153, 'adjacent': 114, 'online': 214, 'instead': 112, 'you': 120, 'ancestor': 77, 'offered': 229, 'used': 25, 'chromosomes': 84, 'closest': 75, 'information': 134, 'may': 117, 'symbol': 111, 'leopard': 157, 'update': 250, 'most': 219, 'wrong': 108, 'connected': 127, 'yosemite': 223, 'such': 53, 'comparison': 1, 'recent': 220, 'a': 33, 'purchase': 204, 'genus': 91, 'kg': 96, 'organisms': 81, 'using': 143, 'starting': 126, 'clear': 130, 'stdin': 147, 'flow': 133, 'roughly': 85, 'so': 238, 'switch': 211, 'without': 151, 'command': 135, 'place': 237, 'allow': 185, 'time': 228, 'redirected': 101, 'the': 11, 'typically': 93, 'left': 131}\n"
     ]
    }
   ],
   "source": [
    "words=dict()\n",
    "numb=0\n",
    "for w in d:\n",
    "    if w not in words:\n",
    "        words[w] = numb\n",
    "        numb += 1\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('in', 0)\n",
      "('comparison', 1)\n",
      "('to', 2)\n",
      "('dogs', 3)\n",
      "('cats', 4)\n",
      "('have', 5)\n",
      "('not', 6)\n",
      "('undergone', 7)\n",
      "('major', 8)\n",
      "('changes', 9)\n",
      "('during', 10)\n",
      "('the', 11)\n",
      "('domestication', 12)\n",
      "('process', 13)\n",
      "('as', 14)\n",
      "('cat', 15)\n",
      "('simply', 16)\n",
      "('catenates', 17)\n",
      "('streams', 18)\n",
      "('of', 19)\n",
      "('bytes', 20)\n",
      "('it', 21)\n",
      "('can', 22)\n",
      "('be', 23)\n",
      "('also', 24)\n",
      "('used', 25)\n",
      "('concatenate', 26)\n",
      "('binary', 27)\n",
      "('files', 28)\n",
      "('where', 29)\n",
      "('will', 30)\n",
      "('just', 31)\n",
      "('sequence', 32)\n",
      "('a', 33)\n",
      "('common', 34)\n",
      "('interactive', 35)\n",
      "('use', 36)\n",
      "('for', 37)\n",
      "('single', 38)\n",
      "('file', 39)\n",
      "('is', 40)\n",
      "('output', 41)\n",
      "('content', 42)\n",
      "('standard', 43)\n",
      "('hear', 44)\n",
      "('sounds', 45)\n",
      "('too', 46)\n",
      "('faint', 47)\n",
      "('or', 48)\n",
      "('high', 49)\n",
      "('frequency', 50)\n",
      "('human', 51)\n",
      "('ears', 52)\n",
      "('such', 53)\n",
      "('those', 54)\n",
      "('made', 55)\n",
      "('by', 56)\n",
      "('mice', 57)\n",
      "('and', 58)\n",
      "('other', 59)\n",
      "('small', 60)\n",
      "('animals', 61)\n",
      "('one', 62)\n",
      "('people', 63)\n",
      "('deliberately', 64)\n",
      "('tamed', 65)\n",
      "('artificial', 66)\n",
      "('selection', 67)\n",
      "('they', 68)\n",
      "('were', 69)\n",
      "('useful', 70)\n",
      "('predators', 71)\n",
      "('vermin', 72)\n",
      "('domesticated', 73)\n",
      "('its', 74)\n",
      "('closest', 75)\n",
      "('wild', 76)\n",
      "('ancestor', 77)\n",
      "('are', 78)\n",
      "('both', 79)\n",
      "('diploid', 80)\n",
      "('organisms', 81)\n",
      "('that', 82)\n",
      "('possess', 83)\n",
      "('chromosomes', 84)\n",
      "('roughly', 85)\n",
      "('genes', 86)\n",
      "('domestic', 87)\n",
      "('similar', 88)\n",
      "('size', 89)\n",
      "('members', 90)\n",
      "('genus', 91)\n",
      "('felis', 92)\n",
      "('typically', 93)\n",
      "('weighing', 94)\n",
      "('between', 95)\n",
      "('kg', 96)\n",
      "('lb', 97)\n",
      "('however', 98)\n",
      "('if', 99)\n",
      "('piped', 100)\n",
      "('redirected', 101)\n",
      "('unnecessary', 102)\n",
      "('with', 103)\n",
      "('named', 104)\n",
      "('safer', 105)\n",
      "('error', 106)\n",
      "('concern', 107)\n",
      "('wrong', 108)\n",
      "('default', 109)\n",
      "('redirection', 110)\n",
      "('symbol', 111)\n",
      "('instead', 112)\n",
      "('often', 113)\n",
      "('adjacent', 114)\n",
      "('on', 115)\n",
      "('keyboards', 116)\n",
      "('may', 117)\n",
      "('permanently', 118)\n",
      "('delete', 119)\n",
      "('you', 120)\n",
      "('needing', 121)\n",
      "('read', 122)\n",
      "('terms', 123)\n",
      "('legibility', 124)\n",
      "('commands', 125)\n",
      "('starting', 126)\n",
      "('connected', 127)\n",
      "('pipes', 128)\n",
      "('has', 129)\n",
      "('clear', 130)\n",
      "('left', 131)\n",
      "('right', 132)\n",
      "('flow', 133)\n",
      "('information', 134)\n",
      "('command', 135)\n",
      "('basic', 136)\n",
      "('learned', 137)\n",
      "('when', 138)\n",
      "('started', 139)\n",
      "('unix', 140)\n",
      "('linux', 141)\n",
      "('world', 142)\n",
      "('using', 143)\n",
      "('lines', 144)\n",
      "('received', 145)\n",
      "('from', 146)\n",
      "('stdin', 147)\n",
      "('new', 148)\n",
      "('symbols', 149)\n",
      "('type', 150)\n",
      "('without', 151)\n",
      "('any', 152)\n",
      "('arguments', 153)\n",
      "('receives', 154)\n",
      "('displays', 155)\n",
      "('stdout', 156)\n",
      "('leopard', 157)\n",
      "('was', 158)\n",
      "('released', 159)\n",
      "('october', 160)\n",
      "('successor', 161)\n",
      "('tiger', 162)\n",
      "('version', 163)\n",
      "('available', 164)\n",
      "('two', 165)\n",
      "('editions', 166)\n",
      "('according', 167)\n",
      "('apple', 168)\n",
      "('contains', 169)\n",
      "('over', 170)\n",
      "('enhancements', 171)\n",
      "('predecessor', 172)\n",
      "('mac', 173)\n",
      "('os', 174)\n",
      "('x', 175)\n",
      "('mid', 176)\n",
      "('some', 177)\n",
      "('computers', 178)\n",
      "('firmware', 179)\n",
      "('factory', 180)\n",
      "('installed', 181)\n",
      "('which', 182)\n",
      "('no', 183)\n",
      "('longer', 184)\n",
      "('allow', 185)\n",
      "('installation', 186)\n",
      "('since', 187)\n",
      "('moved', 188)\n",
      "('intel', 189)\n",
      "('processors', 190)\n",
      "('their', 191)\n",
      "('osx', 192)\n",
      "('community', 193)\n",
      "('developed', 194)\n",
      "('now', 195)\n",
      "('allows', 196)\n",
      "('later', 197)\n",
      "('releases', 198)\n",
      "('non', 199)\n",
      "('based', 200)\n",
      "('mountain', 201)\n",
      "('lion', 202)\n",
      "('july', 203)\n",
      "('purchase', 204)\n",
      "('download', 205)\n",
      "('through', 206)\n",
      "('s', 207)\n",
      "('app', 208)\n",
      "('store', 209)\n",
      "('part', 210)\n",
      "('switch', 211)\n",
      "('releasing', 212)\n",
      "('versions', 213)\n",
      "('online', 214)\n",
      "('every', 215)\n",
      "('year', 216)\n",
      "('patch', 217)\n",
      "('three', 218)\n",
      "('most', 219)\n",
      "('recent', 220)\n",
      "('safari', 221)\n",
      "('running', 222)\n",
      "('yosemite', 223)\n",
      "('mavericks', 224)\n",
      "('release', 225)\n",
      "('marks', 226)\n",
      "('second', 227)\n",
      "('time', 228)\n",
      "('offered', 229)\n",
      "('an', 230)\n",
      "('incremental', 231)\n",
      "('upgrade', 232)\n",
      "('rather', 233)\n",
      "('than', 234)\n",
      "('entirely', 235)\n",
      "('installs', 236)\n",
      "('place', 237)\n",
      "('so', 238)\n",
      "('won', 239)\n",
      "('t', 240)\n",
      "('need', 241)\n",
      "('create', 242)\n",
      "('separate', 243)\n",
      "('disk', 244)\n",
      "('run', 245)\n",
      "('off', 246)\n",
      "('external', 247)\n",
      "('drive', 248)\n",
      "('fifth', 249)\n",
      "('update', 250)\n",
      "('features', 251)\n",
      "('more', 252)\n",
      "('count', 253)\n"
     ]
    }
   ],
   "source": [
    "for znach in (sorted(val for key,val in words.items())):\n",
    "       for key,val in words.items():\n",
    "            if val==znach:\n",
    "                print(key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "M = np.zeros((3, 3))\n",
    "print M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "r = sum(line for line in str if line)\n",
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n"
     ]
    }
   ],
   "source": [
    "print len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1st closest sentence is a sentence #6 with a cosine distance of 0.73.\n",
      "The 2nd closest sentence is a sentence #4 with a cosine distance of 0.78.\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, dot, savetxt\n",
    "from numpy.linalg import norm\n",
    " \n",
    "# Definition of a cosine distance function\n",
    "# according to scipy.spatial.distance.cosine function's description \n",
    "def cosine_distance(u, v):\n",
    "    return 1.0 - (dot(u, v) / (norm(u) * norm(v)))\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"C:\\Users\\leonov\\Documents\\PythonScripts\\sentences.txt\") as f:\n",
    "        # Let's determine a number of lines in a text file\n",
    "        lines = sum(1 for _ in f)\n",
    "        f.seek(0)\n",
    "        \n",
    "        import re\n",
    "        words = {}\n",
    "        # The 'lcount' variable controlls the index of a current line in the text file,\n",
    "        # when the 'wcount' variable controlls the index of a unique word.\n",
    "        lcount, wcount = 0, 0\n",
    "        for line in f:\n",
    "            # Here we compile a pattern object, read a line from the text file,\n",
    "            # and split it into tokens (words).\n",
    "            p = re.compile(r\"[^a-z]+\")\n",
    "            tokens = p.split(line.lower())\n",
    "            # In this case we will have only one empty token at the end of a list.\n",
    "            # Let's remove it.\n",
    "            tokens.pop()\n",
    "            for token in tokens:\n",
    "                # If a token is not presented in the dictionary yet then we add it.\n",
    "                # The value of the 'occurrences' entry is a list object where every item represents\n",
    "                # a specific line in the text file. The first item represents the first line, the second item\n",
    "                # represents the sencond line etc. \n",
    "                if token not in words:\n",
    "                    words[token] = {\n",
    "                        \"index\": wcount,\n",
    "                        \"occurrences\": [0] * lines\n",
    "                    }\n",
    "                    wcount += 1\n",
    "                # If we find the same token in the same list of tokens (in the same line)\n",
    "                # then we just ignore it.\n",
    "                elif words[token][\"occurrences\"][lcount] != 0:\n",
    "                    continue\n",
    "                \n",
    "                # Here we register how many times a token occured in a list of tokens (in a line)    \n",
    "                words[token][\"occurrences\"][lcount] = tokens.count(token)    \n",
    "            lcount += 1\n",
    "        \n",
    "        # Here we create a numpy-array, filled with zeros\n",
    "        arr = zeros((lines, len(words)))\n",
    "        \n",
    "        # Now for every word in the dictionary we take a number of its occurrences\n",
    "        # in every line and put it to the array.  \n",
    "        for word in words:\n",
    "            i, j = 0, words[word][\"index\"]\n",
    "            for occ in words[word][\"occurrences\"]:\n",
    "                arr[i, j] = occ\n",
    "                i += 1\n",
    "    \n",
    "        #savetxt(\"foo.csv\", arr, delimiter=\",\")\n",
    "        \n",
    "        # Finally we calculate a cosine distance between the first sentence (line) and\n",
    "        # other sentences in the text file\n",
    "        dist = [] \n",
    "        u = arr[0,] \n",
    "        for i in range(1, lines):\n",
    "            v = arr[i,]\n",
    "            dist.append({\"index\": i, \"distance\": cosine_distance(u, v)})    \n",
    "        \n",
    "        dist.sort(key=lambda x: x[\"distance\"])\n",
    "        print(\"The 1st closest sentence is a sentence #%d with a cosine distance of %.2f.\\n\"\\\n",
    "        \"The 2nd closest sentence is a sentence #%d with a cosine distance of %.2f.\" % (\n",
    "            dist[0][\"index\"],\n",
    "            dist[0][\"distance\"],\n",
    "            dist[1][\"index\"],\n",
    "            dist[1][\"distance\"]\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
